{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9937058d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/benjamin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/benjamin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "2024-07-09 09:30:29.669964: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import logging\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM, GRU, Bidirectional, Dense, Embedding\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "464aeb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "    '/home/benjamin/Documents/OpenClassroomsDatasets/sentiment/sentiment140/training.1600000.processed.noemoticon.csv',\n",
    "    encoding = \"ISO-8859-1\",\n",
    "    names=[\"target\", \"id\", \"date\", \"flag\", \"user\", \"text\"]\n",
    ")\n",
    "\n",
    "data = data.drop(columns=[\"id\", \"date\", \"flag\", \"user\"])\n",
    "\n",
    "data.target = data.target.map(\n",
    "    {\n",
    "        0: 0.0,\n",
    "        2: 0.0,\n",
    "        4: 1.0,\n",
    "    }\n",
    ")\n",
    "\n",
    "def sample_equal_classes(df, n_pos=100000, n_neg=100000):\n",
    "    df_pos = df[df[\"target\"] == 1.0].sample(n=n_pos)\n",
    "    df_neg = df[df[\"target\"] == 0.0].sample(n=n_neg)\n",
    "    \n",
    "    return pd.concat([df_pos, df_neg]).reset_index(drop=True)\n",
    "sampled_df = sample_equal_classes(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27c8f89d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>got everyth set need wait hour minut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>see juli saw palladium worcest like month ago ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>realli today better good realli hot much coole...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>join lvatt fun gotta problem yet ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>watch lita wwe diva tribut omg favorit diva lo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text\n",
       "0     1.0               got everyth set need wait hour minut\n",
       "1     1.0  see juli saw palladium worcest like month ago ...\n",
       "2     1.0  realli today better good realli hot much coole...\n",
       "3     1.0                join lvatt fun gotta problem yet ph\n",
       "4     1.0  watch lita wwe diva tribut omg favorit diva lo..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tweeter(sentence):\n",
    "    stemmer = PorterStemmer()\n",
    "    tk = TweetTokenizer(preserve_case=False, reduce_len=True)\n",
    "    tok_sent = tk.tokenize(sentence)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = [stemmer.stem(word.lower()) \n",
    "            for word in tok_sent \n",
    "            if word not in stop_words\n",
    "            and word.isalpha()==True]\n",
    "    sent=\"\"\n",
    "    for word in text:\n",
    "        sent+=word+\" \"\n",
    "    return sent[:-1]\n",
    "\n",
    "sampled_df[\"text\"] = sampled_df[\"text\"].apply(lambda x:tweeter(x))\n",
    "sampled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f126f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(min_df=0.001)\n",
    "\n",
    "X = tf.fit_transform(sampled_df['text']).toarray()\n",
    "y = sampled_df[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04cda34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init model\n",
      "initiated\n",
      "Adding SimpleRNN layer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-09 09:52:01.032376: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added\n",
      "Adding Dense layer\n",
      "Added\n",
      "compiling\n",
      "Compiled\n",
      "Training\n",
      "Epoch 1/10\n",
      "    1/40000 [..............................] - ETA: 9:59:05 - loss: 0.6752 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-09 09:52:02.857868: W tensorflow/core/grappler/utils/graph_view.cc:849] No registered '' OpKernel for CPU devices compatible with node {{node sequential/simple_rnn/while/body/_1/sequential/simple_rnn/while/simple_rnn_cell/Relu}}\n",
      "\t.  Registered:  <no registered kernels>\n",
      "\n",
      "2024-07-09 09:52:02.879297: E tensorflow/core/grappler/optimizers/tfg_optimizer_hook.cc:134] tfg_optimizer{any(tfg-consolidate-attrs,tfg-toposort,tfg-shape-inference{graph-version=0},tfg-prepare-attrs-export)} failed: INVALID_ARGUMENT: Node sequential/simple_rnn/while/body/_1/sequential/simple_rnn/while/simple_rnn_cell/Relu has an empty op name\n",
      "\twhen importing GraphDef to MLIR module in GrapplerHook\n",
      "2024-07-09 09:52:02.902166: E tensorflow/core/grappler/optimizers/tfg_optimizer_hook.cc:134] tfg_optimizer{any(tfg-consolidate-attrs,tfg-functional-to-region,tfg.func(tfg-cf-sink),tfg-region-to-functional{force-control-capture=true},tfg-lift-legacy-call,symbol-privatize{},symbol-dce,tfg-prepare-attrs-export)} failed: INVALID_ARGUMENT: Node sequential/simple_rnn/while/body/_1/sequential/simple_rnn/while/simple_rnn_cell/Relu has an empty op name\n",
      "\twhen importing GraphDef to MLIR module in GrapplerHook\n",
      "2024-07-09 09:52:02.902832: E tensorflow/core/grappler/optimizers/tfg_optimizer_hook.cc:134] tfg_optimizer{any(tfg-consolidate-attrs,tfg-functional-to-region,tfg.func(tfg-cf-sink),tfg-region-to-functional{force-control-capture=true},tfg-lift-legacy-call,symbol-privatize{},symbol-dce,tfg-prepare-attrs-export)} failed: INVALID_ARGUMENT: Node sequential/simple_rnn/while/body/_1/sequential/simple_rnn/while/simple_rnn_cell/Relu has an empty op name\n",
      "\twhen importing GraphDef to MLIR module in GrapplerHook\n",
      "2024-07-09 09:52:02.903952: W tensorflow/core/common_runtime/optimize_function_graph_utils.cc:475] Ignoring multi-device function optimization failure: INVALID_ARGUMENT: Node 'sequential/simple_rnn/while/body/_1/sequential/simple_rnn/while/simple_rnn_cell/Relu' does not specify an operation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39993/40000 [============================>.] - ETA: 0s - loss: 0.5235 - accuracy: 0.7354"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-09 09:55:57.089218: W tensorflow/core/grappler/utils/graph_view.cc:849] No registered '' OpKernel for CPU devices compatible with node {{node sequential/simple_rnn/while/body/_1/sequential/simple_rnn/while/simple_rnn_cell/Relu}}\n",
      "\t.  Registered:  <no registered kernels>\n",
      "\n",
      "2024-07-09 09:55:57.095764: E tensorflow/core/grappler/optimizers/tfg_optimizer_hook.cc:134] tfg_optimizer{any(tfg-consolidate-attrs,tfg-toposort,tfg-shape-inference{graph-version=0},tfg-prepare-attrs-export)} failed: INVALID_ARGUMENT: Node sequential/simple_rnn/while/body/_1/sequential/simple_rnn/while/simple_rnn_cell/Relu has an empty op name\n",
      "\twhen importing GraphDef to MLIR module in GrapplerHook\n",
      "2024-07-09 09:55:57.103832: E tensorflow/core/grappler/optimizers/tfg_optimizer_hook.cc:134] tfg_optimizer{any(tfg-consolidate-attrs,tfg-functional-to-region,tfg.func(tfg-cf-sink),tfg-region-to-functional{force-control-capture=true},tfg-lift-legacy-call,symbol-privatize{},symbol-dce,tfg-prepare-attrs-export)} failed: INVALID_ARGUMENT: Node sequential/simple_rnn/while/body/_1/sequential/simple_rnn/while/simple_rnn_cell/Relu has an empty op name\n",
      "\twhen importing GraphDef to MLIR module in GrapplerHook\n",
      "2024-07-09 09:55:57.104110: E tensorflow/core/grappler/optimizers/tfg_optimizer_hook.cc:134] tfg_optimizer{any(tfg-consolidate-attrs,tfg-functional-to-region,tfg.func(tfg-cf-sink),tfg-region-to-functional{force-control-capture=true},tfg-lift-legacy-call,symbol-privatize{},symbol-dce,tfg-prepare-attrs-export)} failed: INVALID_ARGUMENT: Node sequential/simple_rnn/while/body/_1/sequential/simple_rnn/while/simple_rnn_cell/Relu has an empty op name\n",
      "\twhen importing GraphDef to MLIR module in GrapplerHook\n",
      "2024-07-09 09:55:57.104578: W tensorflow/core/common_runtime/optimize_function_graph_utils.cc:475] Ignoring multi-device function optimization failure: INVALID_ARGUMENT: Node 'sequential/simple_rnn/while/body/_1/sequential/simple_rnn/while/simple_rnn_cell/Relu' does not specify an operation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 276s 7ms/step - loss: 0.5236 - accuracy: 0.7354 - val_loss: 0.5145 - val_accuracy: 0.7415\n",
      "Epoch 2/10\n",
      "40000/40000 [==============================] - 276s 7ms/step - loss: 0.5087 - accuracy: 0.7464 - val_loss: 0.5138 - val_accuracy: 0.7427\n",
      "Epoch 3/10\n",
      "40000/40000 [==============================] - 316s 8ms/step - loss: 0.5029 - accuracy: 0.7528 - val_loss: 0.5126 - val_accuracy: 0.7447\n",
      "Epoch 4/10\n",
      "40000/40000 [==============================] - 373s 9ms/step - loss: 0.4982 - accuracy: 0.7564 - val_loss: 0.5117 - val_accuracy: 0.7449\n",
      "Epoch 5/10\n",
      "40000/40000 [==============================] - 341s 9ms/step - loss: 0.4936 - accuracy: 0.7605 - val_loss: 0.5104 - val_accuracy: 0.7474\n",
      "Epoch 6/10\n",
      "40000/40000 [==============================] - 297s 7ms/step - loss: 0.4886 - accuracy: 0.7641 - val_loss: 0.5128 - val_accuracy: 0.7469\n",
      "Epoch 7/10\n",
      "40000/40000 [==============================] - 517s 13ms/step - loss: 0.4826 - accuracy: 0.7680 - val_loss: 0.5137 - val_accuracy: 0.7469\n",
      "Epoch 8/10\n",
      "40000/40000 [==============================] - 569s 14ms/step - loss: 0.4754 - accuracy: 0.7733 - val_loss: 0.5172 - val_accuracy: 0.7473\n",
      "Epoch 9/10\n",
      "40000/40000 [==============================] - 534s 13ms/step - loss: 0.4676 - accuracy: 0.7783 - val_loss: 0.5174 - val_accuracy: 0.7452\n",
      "Epoch 10/10\n",
      "40000/40000 [==============================] - 331s 8ms/step - loss: 0.4594 - accuracy: 0.7841 - val_loss: 0.5226 - val_accuracy: 0.7440\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "print(\"init model\")\n",
    "model = Sequential()\n",
    "print(\"initiated\")\n",
    "print(\"Adding SimpleRNN layer\")\n",
    "model.add(SimpleRNN(128, input_shape=(1, X_train.shape[2]), activation='relu'))\n",
    "print(\"Added\")\n",
    "print(\"Adding Dense layer\")\n",
    "model.add(Dense(1, activation='sigmoid')) \n",
    "print(\"Added\")\n",
    "print(\"compiling\")\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "print(\"Compiled\")\n",
    "\n",
    "print(\"Training\")\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=4, validation_data=(X_test, y_test))\n",
    "\n",
    "# Save the model and vectorizer\n",
    "model.save('model/rnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c26f859c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model/rnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e18d0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_decision(predictions, threshold=0.5):\n",
    "    label=[]\n",
    "    for prediction in predictions:\n",
    "        label.append([1]) if prediction > threshold else label.append([0])\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b8b83d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 10s 8ms/step\n",
      "Accuracy: 0.74395\n",
      "Confusion Matrix:\n",
      " [[14644  5363]\n",
      " [ 4879 15114]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.73      0.74     20007\n",
      "         1.0       0.74      0.76      0.75     19993\n",
      "\n",
      "    accuracy                           0.74     40000\n",
      "   macro avg       0.74      0.74      0.74     40000\n",
      "weighted avg       0.74      0.74      0.74     40000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "decisions = make_decision(y_pred)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, decisions))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, decisions))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, decisions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5c47f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

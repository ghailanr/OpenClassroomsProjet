{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa5e16c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/benjamin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/benjamin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# import dask.dataframe as dd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import logging\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0291a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "    '/home/benjamin/Documents/OpenClassroomsDatasets/sentiment/sentiment140/training.1600000.processed.noemoticon.csv',\n",
    "    encoding = \"ISO-8859-1\",\n",
    "    names=[\"target\", \"id\", \"date\", \"flag\", \"user\", \"text\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba155b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70c4b207",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=[\"id\", \"date\", \"flag\", \"user\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ab534c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.target = data.target.map(\n",
    "    {\n",
    "        0: \"NEGATIVE\",\n",
    "        2: \"NEUTRAL\",\n",
    "        4: \"POSITIVE\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c1b6530",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_equal_classes(df, n_pos=100000, n_neg=100000):\n",
    "    df_pos = df[df[\"target\"] == \"POSITIVE\"].sample(n=n_pos)\n",
    "    df_neg = df[df[\"target\"] == \"NEGATIVE\"].sample(n=n_neg)\n",
    "    \n",
    "    return pd.concat([df_pos, df_neg]).reset_index(drop=True)\n",
    "sampled_df = sample_equal_classes(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9ed703b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_dataframe_memory_usage(\n",
    "    df: pd.DataFrame,\n",
    "    high_precision: bool = False,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Iterate through all the columns of a dataframe and modify the data type to\n",
    "    reduce memory usage.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): dataframe to reduce memory usage.\n",
    "        high_precision (bool): If True, use 64-bit floats instead of 32-bit\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: dataframe with reduced memory usage.\n",
    "    \"\"\"\n",
    "    start_mem = round(df.memory_usage().sum() / 1024**2, 2)\n",
    "    logging.info(\"Memory usage of dataframe is %d MB\", start_mem)\n",
    "\n",
    "    # Iterate through columns\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == \"object\":\n",
    "            # \"object\" dtype\n",
    "            if df[col].nunique() < max(100, df.shape[0] / 100):\n",
    "                # If number of unique values is less than max(100, 1%)\n",
    "                df[col] = df[col].astype(\"category\")\n",
    "            else:\n",
    "                # If number of unique values is greater than max(100, 1%)\n",
    "                df[col] = df[col].astype(\"string\")\n",
    "\n",
    "        elif str(df[col].dtype)[:3] == \"int\":\n",
    "            # \"int\" dtype\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if c_min > np.iinfo(np.uint8).min and c_max < np.iinfo(np.uint8).max:\n",
    "                df[col] = df[col].astype(\"UInt8\")\n",
    "            elif c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                df[col] = df[col].astype(\"Int8\")\n",
    "            elif c_min > np.iinfo(np.uint16).min and c_max < np.iinfo(np.uint16).max:\n",
    "                df[col] = df[col].astype(\"UInt16\")\n",
    "            elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                df[col] = df[col].astype(\"Int16\")\n",
    "            elif c_min > np.iinfo(np.uint32).min and c_max < np.iinfo(np.uint32).max:\n",
    "                df[col] = df[col].astype(\"UInt32\")\n",
    "            elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                df[col] = df[col].astype(\"Int32\")\n",
    "            elif c_min > np.iinfo(np.uint64).min and c_max < np.iinfo(np.uint64).max:\n",
    "                df[col] = df[col].astype(\"UInt64\")\n",
    "            else:\n",
    "                df[col] = df[col].astype(\"Int64\")\n",
    "\n",
    "        elif str(df[col].dtype)[:5] == \"float\":\n",
    "            # \"float\" dtype\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if (\n",
    "                not high_precision\n",
    "                and c_min > np.finfo(np.float32).min\n",
    "                and c_max < np.finfo(np.float32).max\n",
    "            ):\n",
    "                df[col] = df[col].astype(\"float32\")\n",
    "            else:\n",
    "                df[col] = df[col].astype(\"float64\")\n",
    "\n",
    "    end_mem = round(df.memory_usage().sum() / 1024**2, 2)\n",
    "    logging.info(\"Memory usage after optimization is %d MB\", end_mem)\n",
    "    if start_mem > 0:\n",
    "        logging.info(\n",
    "            \"Decreased by %d %%\", round(100 * (start_mem - end_mem) / start_mem)\n",
    "        )\n",
    "\n",
    "    return df\n",
    "\n",
    "sampled_df = reduce_dataframe_memory_usage(sampled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80bf4aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweeter(sentence):\n",
    "    stemmer = PorterStemmer()\n",
    "    tk = TweetTokenizer(preserve_case=False, reduce_len=True)\n",
    "    tok_sent = tk.tokenize(sentence)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = [stemmer.stem(word.lower()) \n",
    "            for word in tok_sent \n",
    "            if word not in stop_words\n",
    "            and word.isalpha()==True]\n",
    "    sent=\"\"\n",
    "    for word in text:\n",
    "        sent+=word+\" \"\n",
    "    return sent[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7a33b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>go shop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>oh movi sooo much wonder although need grovel end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>use tryin get shape</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>thank respons ye inde figur respons trial erro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>yep enjoy movi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     target                                               text\n",
       "0  POSITIVE                                            go shop\n",
       "1  POSITIVE  oh movi sooo much wonder although need grovel end\n",
       "2  POSITIVE                                use tryin get shape\n",
       "3  POSITIVE  thank respons ye inde figur respons trial erro...\n",
       "4  POSITIVE                                     yep enjoy movi"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_df[\"text\"] = sampled_df[\"text\"].apply(lambda x:tweeter(x))\n",
    "sampled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4082d385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((160000, 959), (40000, 959))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "tf = TfidfVectorizer(min_df=0.001)\n",
    "\n",
    "X = tf.fit_transform(sampled_df['text']).toarray()\n",
    "y = sampled_df[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8f6db42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Logistic Regression model\n",
    "logistic_model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "logistic_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b0ae2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.745075\n",
      "Confusion Matrix:\n",
      " [[14273  5734]\n",
      " [ 4463 15530]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.76      0.71      0.74     20007\n",
      "    POSITIVE       0.73      0.78      0.75     19993\n",
      "\n",
      "    accuracy                           0.75     40000\n",
      "   macro avg       0.75      0.75      0.74     40000\n",
      "weighted avg       0.75      0.75      0.74     40000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7a3895b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: ['POSITIVE' 'NEGATIVE' 'POSITIVE']\n"
     ]
    }
   ],
   "source": [
    "# Example new text data\n",
    "new_text = [\"This is an example sentence.\",\n",
    "            \"What a stupid idea !\",\n",
    "            \"Truly incredible comeback !\"]\n",
    "\n",
    "# Preprocess and transform the new text data to TF-IDF features\n",
    "new_text_processed = [tweeter(text) for text in new_text]\n",
    "new_text_tfidf = tf.transform(new_text_processed).toarray()\n",
    "\n",
    "# Make predictions\n",
    "predictions = logistic_model.predict(new_text_tfidf)\n",
    "print(\"Predictions:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1178b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle_out = open(\"log_reg.pkl\",\"wb\")\n",
    "pickle.dump(logistic_model, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4b1d7618",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open(\"tfidf.pkl\",\"wb\")\n",
    "pickle.dump(tf, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a00c7e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Prediction\":\"POSITIVE\"}\n"
     ]
    }
   ],
   "source": [
    "#test API\n",
    "import requests\n",
    "\n",
    "test = \"Incredibly done !\"\n",
    "url = \"http://127.0.0.1:8000/predict\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "body = {\n",
    "    \"text\" : test\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=body, headers=headers)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(response.text)\n",
    "else:\n",
    "    print(f\"Erreur : {response.status_code} : {response.reason}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765aa0ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
